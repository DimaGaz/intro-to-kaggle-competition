{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4162a6a",
   "metadata": {},
   "source": [
    "#  1. Kaggle competitions process\n",
    "The data for this exercise is coming from the [Store Item Demand Forecasting Challenge](https://www.kaggle.com/competitions/demand-forecasting-kernels-only/data).\n",
    "\n",
    "## Training data exploration\n",
    "We are given 5 years of store-item sales data, and asked to predict 3 months of sales for 50 different items in 10 different stores. To begin, we will explore the train data for this competition. For the faster performance, we will work with a subset of the train data containing only ~25% of it. Our initial goal is to read the input data and take the first look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d0d004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/\n",
    "import sys\n",
    "# !conda install --yes --prefix {sys.prefix} pandas\n",
    "# !conda install --yes --prefix {sys.prefix} mkl-service\n",
    "# !conda install --yes --prefix {sys.prefix} numpy\n",
    "# !conda install --yes --prefix {sys.prefix} matplotlib\n",
    "# !conda install --yes --prefix {sys.prefix} scikit-learn\n",
    "# !conda install --yes --prefix {sys.prefix} xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70017f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd617d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (228250, 4)\n",
      "              date  store  item  sales\n",
      "684750  2013-01-01      6    38     31\n",
      "684751  2013-01-02      6    38     20\n",
      "684752  2013-01-03      6    38     37\n",
      "684753  2013-01-04      6    38     41\n",
      "684754  2013-01-05      6    38     50\n"
     ]
    }
   ],
   "source": [
    "# Read train data\n",
    "dir = 'data/store_item_demand_forecasting_challenge/'\n",
    "train = pd.read_csv(dir + 'train.csv')\n",
    "\n",
    "# Look at the shape of the data\n",
    "train = train[int(0.75*train.shape[0]):] # take the latest 25% of the data\n",
    "print('Train shape:', train.shape)\n",
    "\n",
    "# Look at the head() of the data\n",
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a367d72",
   "metadata": {},
   "source": [
    "Having looked at the train data, let's explore the test data in the \"Store Item Demand Forecasting Challenge\". Remember, that the test dataset generally contains one column less than the train one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c82eec82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns: ['date', 'store', 'item', 'sales']\n",
      "Test columns: ['id', 'date', 'store', 'item']\n"
     ]
    }
   ],
   "source": [
    "# Read the test data\n",
    "test = pd.read_csv(dir + 'test.csv')\n",
    "\n",
    "# Print train and test columns\n",
    "print('Train columns:', train.columns.tolist())\n",
    "print('Test columns:', test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60aa361",
   "metadata": {},
   "source": [
    "Let's have a look at the submission file to get the output format for the Kaggle competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6541db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  sales\n",
      "0   0     52\n",
      "1   1     52\n",
      "2   2     52\n",
      "3   3     52\n",
      "4   4     52\n"
     ]
    }
   ],
   "source": [
    "# Read the sample submission file\n",
    "sample_submission = pd.read_csv(dir + 'sample_submission.csv')\n",
    "\n",
    "# Look at the head() of the sample submission\n",
    "print(sample_submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5510d2f",
   "metadata": {},
   "source": [
    "The sample submission file consists of two columns: `id` of the observation and `sales` column for your predictions. Kaggle will evaluate your predictions on the true `sales` data for the corresponding `id`. So, itâ€™s important to keep track of the predictions by `id` before submitting them.\n",
    "\n",
    "To determine a problem type let's explore the target variable `sales` in the the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a444a770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train.sales.hist(bins=30, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d994eff",
   "metadata": {},
   "source": [
    "## Prepare a submission\n",
    "The `sales` variable is continuous, so we're solving a regression problem. Now we're ready to build a model for a subsequent submission. For this exercise we will use `RandomForestRegressor` class from the `scikit-learn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d8f8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest object\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Train a model on the \"store\" and \"item\" features with \"sales\" as a target.\n",
    "rf.fit(X=train[['store', 'item']], y=train['sales'])\n",
    "\n",
    "# Get predictions for the test set\n",
    "test['sales'] = rf.predict(test[['store', 'item']])\n",
    "\n",
    "# Write test predictions using the sample_submission format (Note that sample submission has id and sales columns).\n",
    "test[['id', 'sales']].to_csv('kaggle_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba43c8c",
   "metadata": {},
   "source": [
    "We've prepared our first Kaggle submission. Now, we could upload it to the Kaggle platform and see our score and current position on the Leaderboard. \n",
    "\n",
    "## Overfitting\n",
    "Every Machine Learning method could potentially overfit. We will see it on this example with XGBoost. Firstly, let's train multiple XGBoost models with different sets of hyperparameters using XGBoost's learning API. The single hyperparameter we will change is:\n",
    "- `max_depth` - maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ffe4d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DmitriGazizulin\\anaconda3\\envs\\intro-to-kaggle-competition\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    }
   ],
   "source": [
    "# Create DMatrix on train data\n",
    "dtrain = xgb.DMatrix(data=train[['store', 'item']],\n",
    "                     label=train['sales'])\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {'objective': 'reg:squarederror',\n",
    "          'max_depth': 2,\n",
    "          'verbosity': 1}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_2 = xgb.train(params=params, dtrain=dtrain)\n",
    "\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {'objective': 'reg:squarederror',\n",
    "          'max_depth': 8,\n",
    "          'verbosity': 1}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_8 = xgb.train(params=params, dtrain=dtrain)\n",
    "\n",
    "# Define xgboost parameters\n",
    "params = {'objective': 'reg:squarederror',\n",
    "          'max_depth': 15,\n",
    "          'verbosity': 1}\n",
    "\n",
    "# Train xgboost model\n",
    "xg_depth_15 = xgb.train(params=params, dtrain=dtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2fc100",
   "metadata": {},
   "source": [
    "Having trained 3 XGBoost models with different maximum depths, we will now evaluate their quality. For this purpose, we will measure the quality of each model on both the train data and the test data (assuming that the predictions from the Random Forest were correct). \n",
    "\n",
    "The goal of this exercise is to determine whether any of the models trained is overfitting. To measure the quality of the models we will use Mean Squared Error (MSE). It's available in sklearn.metrics as mean_squared_error() function that takes two arguments: true values and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74bab343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DmitriGazizulin\\anaconda3\\envs\\intro-to-kaggle-competition\\lib\\site-packages\\xgboost\\data.py:250: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train: 328.703. MSE Test: 93.959\n",
      "MSE Train: 194.991. MSE Test: 7.306\n",
      "MSE Train: 194.580. MSE Test: 3.409\n"
     ]
    }
   ],
   "source": [
    "# Create DMatrix on test data\n",
    "dtest = xgb.DMatrix(data=test[['store', 'item']])\n",
    "\n",
    "# For each of 3 trained models\n",
    "for model in [xg_depth_2, xg_depth_8, xg_depth_15]:\n",
    "    # make predictions\n",
    "    train_pred = model.predict(dtrain)\n",
    "    test_pred = model.predict(dtest)\n",
    "    \n",
    "    # calculate metrics\n",
    "    mse_train = mean_squared_error(train['sales'], train_pred)\n",
    "    mse_test = mean_squared_error(test['sales'], test_pred)\n",
    "    print('MSE Train: {:.3f}. MSE Test: {:.3f}'.format(mse_train, mse_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55756c94",
   "metadata": {},
   "source": [
    "In these case we don't see an overfit since we don't have the real labels of the test set. However, this exercice was a good practice to conduct an overfit analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro-to-kaggle-copetition",
   "language": "python",
   "name": "intro-to-kaggle-copetition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
